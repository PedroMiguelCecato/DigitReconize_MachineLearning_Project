{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f72200b",
   "metadata": {},
   "source": [
    "# Filtrando dígitos 1 e 5 e treinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c14255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f206f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2186, 3)\n",
      "Test shape: (1115, 3)\n",
      "   label  intensidade   simetria\n",
      "0      0    145.43529  148.57256\n",
      "1      0    118.57647  137.11372\n",
      "2      0    127.60000  134.04706\n",
      "3      0    138.04706  151.00392\n",
      "4      0    146.21568  122.50196\n"
     ]
    }
   ],
   "source": [
    "train_redu = pd.read_csv(\"dataset_digits/train_redu.csv\")\n",
    "test_redu  = pd.read_csv(\"dataset_digits/test_redu.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_redu.shape)\n",
    "print(\"Test shape:\", test_redu.shape)\n",
    "print(train_redu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266470f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1x5 = train_redu[train_redu[\"label\"].isin([1, 5])].copy()\n",
    "test1x5  = test_redu[test_redu[\"label\"].isin([1, 5])].copy()\n",
    "\n",
    "# Criação da variável-alvo y (+1 para dígito 1 e -1 para dígito 5)\n",
    "train1x5[\"y\"] = train1x5[\"label\"].apply(lambda x: 1 if x == 1 else -1)\n",
    "test1x5[\"y\"]  = test1x5[\"label\"].apply(lambda x: 1 if x == 1 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24d40eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificação das dimensões ---\n",
      "Tamanho treino: (947, 2)\n",
      "Tamanho validação: (237, 2)\n",
      "Tamanho teste: (583, 2)\n"
     ]
    }
   ],
   "source": [
    "X_1x5 = train1x5[[\"intensidade\", \"simetria\"]].values.astype(float)\n",
    "y = train1x5[\"y\"].values.astype(int)\n",
    "\n",
    "X_train_1x5, X_val_1x5, y_train, y_val = train_test_split(\n",
    "    X_1x5, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_test_1x5 = test1x5[[\"intensidade\", \"simetria\"]].values.astype(float)\n",
    "y_test = test1x5[\"y\"].values.astype(int)\n",
    "\n",
    "# Escalonamento dos dados (0 a 1)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_1x5)\n",
    "X_val   = scaler.transform(X_val_1x5)\n",
    "X_test  = scaler.transform(X_test_1x5)\n",
    "\n",
    "print(\"\\n--- Verificação das dimensões ---\")\n",
    "print(\"Tamanho treino:\", X_train.shape)\n",
    "print(\"Tamanho validação:\", X_val.shape)\n",
    "print(\"Tamanho teste:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba08c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class PocketPLA:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def get_w(self):\n",
    "        return self.w\n",
    "    \n",
    "    def set_w(self, w):\n",
    "        self.w = w\n",
    "\n",
    "    def execute(self, X, y, max_iter=1000):\n",
    "        # Inicializa w com zeros\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "\n",
    "        # Guarda o melhor w e o menor erro\n",
    "        pocket_w = self.w.copy()\n",
    "        best_error = self.errorIN(X, y)\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            atualizado = False\n",
    "            for i in range(len(y)):\n",
    "                if np.sign(np.dot(self.w, X[i])) != y[i]:\n",
    "                    # Atualiza pesos\n",
    "                    self.w += y[i] * X[i]\n",
    "                    atualizado = True\n",
    "\n",
    "                    # Calcula erro atual\n",
    "                    current_error = self.errorIN(X, y)\n",
    "\n",
    "                    # Se o novo w for melhor, guarda no pocket\n",
    "                    if current_error < best_error:\n",
    "                        pocket_w = self.w.copy()\n",
    "                        best_error = current_error\n",
    "                    break  # volta a percorrer o dataset do início\n",
    "\n",
    "            # Se não houve atualização, já convergiu\n",
    "            if not atualizado:\n",
    "                break\n",
    "\n",
    "        # Usa o melhor w encontrado\n",
    "        self.w = pocket_w\n",
    "\n",
    "    def getOriginalY(self, originalX):\n",
    "        return (-self.w[0] - self.w[1]*originalX) / self.w[2]\n",
    "    \n",
    "    def h(self, x):\n",
    "        return np.sign(np.dot(self.w, x))\n",
    "    \n",
    "    def errorIN(self, X, y):\n",
    "        erros = 0\n",
    "        for i in range(len(y)):\n",
    "            if np.sign(np.dot(self.w, X[i])) != y[i]:\n",
    "                erros += 1\n",
    "        return erros\n",
    "    \n",
    "# === Adiciona o bias ao conjunto de treino, validação e teste ===\n",
    "X_train_bias = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "X_val_bias   = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
    "X_test_bias  = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892b407",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2dcb427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PocketPLA:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def get_w(self):\n",
    "        return self.w\n",
    "    \n",
    "    def set_w(self, w):\n",
    "        self.w = w\n",
    "\n",
    "    def execute(self, X, y, max_iter=1000):\n",
    "        # Adiciona bias internamente\n",
    "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "        # Inicializa w como vetor de zeros\n",
    "        self.w = np.zeros(X_bias.shape[1])\n",
    "\n",
    "        # Armazena o melhor w (pocket) e o menor erro\n",
    "        pocket_w = self.w.copy()\n",
    "        best_error = self.errorIN(X_bias, y)\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            for i in range(len(y)):\n",
    "                if np.sign(np.dot(self.w, X_bias[i])) != y[i]:\n",
    "                    # Atualiza w com erro atual\n",
    "                    self.w += y[i] * X_bias[i]\n",
    "\n",
    "                    # Calcula erro com novo w\n",
    "                    current_error = self.errorIN(X_bias, y)\n",
    "\n",
    "                    # Se for melhor, guarda no pocket\n",
    "                    if current_error < best_error:\n",
    "                        pocket_w = self.w.copy()\n",
    "                        best_error = current_error\n",
    "                    break  # volta ao início do loop principal\n",
    "\n",
    "        # Ao final, define o melhor w encontrado\n",
    "        self.w = pocket_w\n",
    "    \n",
    "    def getOriginalY(self, originalX):\n",
    "        \"\"\"Calcula Y original da fronteira de decisão (para plot 2D).\"\"\"\n",
    "        return (-self.w[0] - self.w[1]*originalX) / self.w[2]\n",
    "\n",
    "    def h(self, x):\n",
    "        # Adiciona bias automaticamente ao vetor de entrada\n",
    "        x_bias = np.insert(x, 0, 1)  # insere o 1 no início\n",
    "        return np.sign(np.dot(self.w, x_bias))\n",
    "    \n",
    "    def errorIN(self, X_bias, y):\n",
    "        error = 0\n",
    "        for i in range(len(y)):\n",
    "            if np.sign(np.dot(self.w, X_bias[i])) != y[i]:\n",
    "                error += 1\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb8df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vetor de pesos treinado ---\n",
      "[ 1.         -0.92235091 -0.66832498]\n",
      "\n",
      "--- Predições no conjunto de teste ---\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# === Treina o modelo PocketPLA ===\n",
    "perceptron = PocketPLA()\n",
    "perceptron.execute(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- Vetor de pesos treinado ---\")\n",
    "print(perceptron.w)\n",
    "\n",
    "# === Predição no conjunto de teste ===\n",
    "y_pred = np.array([perceptron.h(x) for x in X_test])\n",
    "\n",
    "print(\"\\n--- Predições no conjunto de teste ---\")\n",
    "print(y_pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f5a9ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class RegressaoLinear:\\n    def __init__(self):\\n        self.w = None\\n\\n    def fit(self, X, y):\\n        X = np.array(X)\\n        y = np.array(y)\\n\\n        n_samples, n_features = X.shape\\n\\n        # Adiciona bias (coluna de 1s)\\n        X = np.hstack([X, np.ones((n_samples, 1))])\\n\\n        # Solução analítica: w = (X^T X)^-1 X^T y\\n        self.w = np.linalg.pinv(X.T @ X) @ (X.T @ y)\\n\\n    def predict(self, X, class_output=True):\\n        # Adiciona bias\\n        X_bias = np.c_[X, np.ones(X.shape[0])]\\n\\n        # Predição contínua\\n        y_pred = X_bias @ self.w\\n\\n        # Se class_output=True, converte para classes -1 / +1\\n        if class_output:\\n            y_class = np.sign(y_pred)\\n            y_class[y_class == 0] = 1\\n            return y_class\\n\\n        return y_pred\\n    \\nlinreg = RegressaoLinear()\\nlinreg.fit(X_train, y_train)\\n\\nprint(\"\\n--- Regressão Linear ---\")\\nprint(\"Vetor de pesos treinado:\", linreg.w)\\ny_pred_lin_class = linreg.predict(X_test)\\ny_pred_lin_cont = linreg.predict(X_test, class_output=False)\\nprint(\"Predições (classe):\", y_pred_lin_class[:10])\\nprint(\"Predições (contínuas):\", y_pred_lin_cont[:10])'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class RegressaoLinear:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Adiciona bias (coluna de 1s)\n",
    "        X = np.hstack([X, np.ones((n_samples, 1))])\n",
    "\n",
    "        # Solução analítica: w = (X^T X)^-1 X^T y\n",
    "        self.w = np.linalg.pinv(X.T @ X) @ (X.T @ y)\n",
    "\n",
    "    def predict(self, X, class_output=True):\n",
    "        # Adiciona bias\n",
    "        X_bias = np.c_[X, np.ones(X.shape[0])]\n",
    "\n",
    "        # Predição contínua\n",
    "        y_pred = X_bias @ self.w\n",
    "\n",
    "        # Se class_output=True, converte para classes -1 / +1\n",
    "        if class_output:\n",
    "            y_class = np.sign(y_pred)\n",
    "            y_class[y_class == 0] = 1\n",
    "            return y_class\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "linreg = RegressaoLinear()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- Regressão Linear ---\")\n",
    "print(\"Vetor de pesos treinado:\", linreg.w)\n",
    "y_pred_lin_class = linreg.predict(X_test)\n",
    "y_pred_lin_cont = linreg.predict(X_test, class_output=False)\n",
    "print(\"Predições (classe):\", y_pred_lin_class[:10])\n",
    "print(\"Predições (contínuas):\", y_pred_lin_cont[:10])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72879710",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8d76144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def execute(self, _X, _y, show=False):\n",
    "        X0 = np.asarray(_X, dtype=float)\n",
    "        y = np.asarray(_y, dtype=float).ravel()\n",
    "\n",
    "        # Garante formato 2D\n",
    "        if X0.ndim == 1:\n",
    "            X0 = X0.reshape(-1, 1)\n",
    "\n",
    "        # Matriz de projeto\n",
    "        X = np.c_[np.ones((X0.shape[0], 1)), X0]\n",
    "\n",
    "        if show:\n",
    "            print(\"X =\\n\", X)\n",
    "            print(\"y =\\n\", y)\n",
    "\n",
    "        # Solução via pseudo-inversa (SVD internamente)\n",
    "        self.w = np.linalg.pinv(X) @ y\n",
    "\n",
    "        if show:\n",
    "            print(f\"W =\\n{self.w}\")\n",
    "\n",
    "    def predict(self, _x, class_output=False):\n",
    "        x0 = np.asarray(_x, dtype=float)\n",
    "        if x0.ndim == 1:\n",
    "            x0 = x0.reshape(1, -1)\n",
    "\n",
    "        X = np.c_[np.ones((x0.shape[0], 1)), x0]\n",
    "        y_pred = X @ self.w\n",
    "\n",
    "        if class_output:\n",
    "            y_class = np.sign(y_pred)\n",
    "            y_class[y_class == 0] = 1\n",
    "            return y_class\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def get_w(self):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b728320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treinando Regressão Linear ===\n",
      "--- Vetor de pesos (Regressão Linear) ---\n",
      "[ 1.56309114 -1.39341773 -1.77398181]\n",
      "\n",
      "Predições (valores contínuos): [1.1289766  0.83943899 1.232256   0.92278039 0.98800396 1.1328054\n",
      " 0.74303143 0.66856743 1.38109177 1.2276304 ]\n",
      "Predições (classe): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Treinando Regressão Linear ===\")\n",
    "linreg = LinearRegression()\n",
    "linreg.execute(X_train, y_train)\n",
    "\n",
    "print(\"--- Vetor de pesos (Regressão Linear) ---\")\n",
    "print(linreg.get_w())\n",
    "\n",
    "print(\"\\nPredições (valores contínuos):\", linreg.predict(X_test)[:10])\n",
    "print(\"Predições (classe):\", linreg.predict(X_test, class_output=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c3ad2",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e061dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressaoLogistica:\n",
    "    def __init__(self, eta=0.01, tmax=5000, lambda_=0.01):\n",
    "        self.eta = eta\n",
    "        self.tmax = tmax\n",
    "        self.lambda_ = lambda_\n",
    "        self.w = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.where(np.array(y) <= 0, -1, 1)\n",
    "\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        n_amostras, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "\n",
    "        for _ in range(self.tmax):\n",
    "            z = X @ self.w\n",
    "            grad = -(1/n_amostras) * (X.T @ (y / (1 + np.exp(y * z))))\n",
    "            grad[1:] += self.lambda_ * self.w[1:]\n",
    "            self.w -= self.eta * grad\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        X = np.array(X)\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return self.sigmoid(X @ self.w)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return np.sign(X @ self.w)\n",
    "\n",
    "    def get_w(self):\n",
    "        return self.w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91b50f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treinando Regressão Logística ===\n",
      "--- Vetor de pesos (Regressão Logística) ---\n",
      "[ 3.34592856 -3.28596798 -3.49240159]\n",
      "Predições (classe): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Probabilidades (sigmoid): [0.91941264 0.86577698 0.93632255 0.88442099 0.89198937 0.91752953\n",
      " 0.83922462 0.81609309 0.95041987 0.93523833]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Treinando Regressão Logística ===\")\n",
    "logreg = RegressaoLogistica(eta=0.1, tmax=5000, lambda_=0.01)\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"--- Vetor de pesos (Regressão Logística) ---\")\n",
    "print(logreg.get_w())\n",
    "print(\"Predições (classe):\", logreg.predict(X_test)[:10])\n",
    "print(\"Probabilidades (sigmoid):\", logreg.predict_prob(X_test)[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
